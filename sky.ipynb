{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a88faaa8-247a-44e6-85a5-0678e9e36732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\badar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2746 - loss: 1.1148 - val_accuracy: 0.4167 - val_loss: 1.0546\n",
      "Epoch 2/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4553 - loss: 1.0520 - val_accuracy: 0.6250 - val_loss: 1.0154\n",
      "Epoch 3/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4883 - loss: 1.0422 - val_accuracy: 0.7083 - val_loss: 0.9787\n",
      "Epoch 4/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7834 - loss: 0.9714 - val_accuracy: 0.8333 - val_loss: 0.9392\n",
      "Epoch 5/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8742 - loss: 0.9431 - val_accuracy: 0.8333 - val_loss: 0.9030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8667 - loss: 0.9161\n",
      "\n",
      "Test Accuracy: 86.67%\n"
     ]
    }
   ],
   "source": [
    "# 1).Develop a program to build and train a feedforward  neural network from scratch using a deep learning \n",
    "# framework like TensorFlow, keras etc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(10, input_shape=(4,), activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=8, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f4a303-c1af-441c-a96c-01fd8a43a571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\badar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3264 - loss: 2.5256\n",
      "Epoch 2/3\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7140 - loss: 1.0993\n",
      "Epoch 3/3\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7746 - loss: 0.8397\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8011 - loss: 0.7115\n",
      "\n",
      "Test Accuracy: 79.75%\n"
     ]
    }
   ],
   "source": [
    "# 2).Multiclass classification using Deep Neural Networks: Example: Use the OCR letter recognition dataset\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\"\n",
    "columns = ['letter'] + [f'feat{i}' for i in range(1, 17)]\n",
    "data = pd.read_csv(url, names=columns)\n",
    "\n",
    "X = data.iloc[:, 1:].values  # features\n",
    "y = LabelEncoder().fit_transform(data['letter'])  # A-Z to 0-25\n",
    "y = to_categorical(y, num_classes=26)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(16,)),\n",
    "    tf.keras.layers.Dense(26, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=32)\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9dc5f80-e6d4-40f7-97f1-01270d8d3e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6582 - loss: 0.6470\n",
      "Epoch 2/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8453 - loss: 0.4099\n",
      "Epoch 3/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8816 - loss: 0.3106\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      "Review 1:\n",
      "? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? please give this one a miss br br ? ? and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite ? so all you madison fans give this a miss\n",
      "Sentiment: Negative\n",
      "\n",
      "Review 2:\n",
      "psychological ? it's very interesting that robert altman directed this considering the style and structure of his other films still the trademark altman audio style is evident here and there i think what really makes this film work is the brilliant performance by sandy dennis it's definitely one of her darker characters but she plays it so perfectly and convincingly that it's scary michael burns does a good job as the mute young man regular altman player michael murphy has a small part the ? moody set fits the content of the story very well in short this movie is a powerful study of loneliness sexual ? and desperation be patient ? up the atmosphere and pay attention to the wonderfully written script br br i praise robert altman this is one of his many films that deals with unconventional fascinating subject matter this film is disturbing but it's sincere and it's sure to ? a strong emotional response from the viewer if you want to see an unusual film some might even say bizarre this is worth the time br br unfortunately it's very difficult to find in video stores you may have to buy it off the internet\n",
      "Sentiment: Positive\n",
      "\n",
      "Review 3:\n",
      "everyone's horror the ? promptly eats the mayor and then goes on a merry rampage ? citizens at random a title card ? reads news of the king's ? throughout the kingdom when the now terrified ? once more ? ? for help he loses his temper and ? their community with lightning ? the moral of our story delivered by a hapless frog just before he is eaten is let well enough alone br br considering the time period when this startling little film was made and considering the fact that it was made by a russian ? at the height of that ? country's civil war it would be easy to see this as a ? about those events ? may or may not have had ? turmoil in mind when he made ? but whatever ? his choice of material the film stands as a ? tale of universal ? ? could be the soviet union italy germany or japan in the 1930s or any country of any era that lets its guard down and is overwhelmed by ? it's a fascinating film even a charming one in its macabre way but its message is no joke\n",
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "# 3)Binary classification using Deep Neural Networks Example: Classify movie reviews into positive \"reviews and \"negative\" reviews, just based on the \n",
    "# text content of the reviews. Use IMDB dataset.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=200)\n",
    "x_test = pad_sequences(x_test, maxlen=200)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 32, input_length=200),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=32)\n",
    "\n",
    "predictions = model.predict(x_test[:3])\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = {i: word for word, i in word_index.items()}\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in text])  # Adjust for special tokens\n",
    "for i in range(3):\n",
    "    print(f\"\\nReview {i+1}:\")\n",
    "    print(decode_review(x_test[i]))\n",
    "    print(\"Sentiment:\", \"Positive\" if predictions[i] > 0.5 else \"Negative\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddc83890-2a2e-49c0-922d-945d5adcc042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\badar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8985 - loss: 0.3561\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9846 - loss: 0.0553\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9906 - loss: 0.0324\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9928 - loss: 0.0232\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9954 - loss: 0.0151\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9732 - loss: 0.0800\n",
      "Test accuracy: 0.9801\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001FB788071A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHjlJREFUeJzt3XlsFOcZx/HHENuYw+bGdjDG3BFnIUAQhHDFBFIEgagh8AdEFAoFGnCBBBTORHJLK0qhhKhShZuKI0EKoKDULacpiSGFhCKnQMElAQTmCl5jE05P9b7IWy+2gTG7fta734/0st7deXdexuP57TvzzkyE4ziOAABQxWpU9QwBADAIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggoBJatmwpEydO9D7fu3evRERE2MdgbSMQbAggVDsZGRl2Y19SatWqJe3atZMZM2bIxYsXpTr57LPPZMmSJRJsTJtKL+MHy+eff67dRISAp7QbAFTWsmXLJCUlRW7evCn79++XtWvX2g16Tk6O1K5du0rb0r9/f/nhhx8kKirKVT3T3jVr1gRdCI0ePVratGlT5vUFCxZIYWGh9OzZU6VdCC0EEKqtYcOGybPPPmt//ulPfyqNGjWSFStWyLZt2+T1118vt05RUZHUqVPH722pUaOG7YmFii5duthS2tmzZ+XcuXN2WbsNWqA87IJDyBg0aJB9PH36tH00xz/q1q0rubm5Mnz4cKlXr56MHz/evldcXCwrV66Ujh072uBo1qyZ/OxnP5Nr1675fKa5WPx7770nzZs3t72qgQMHyjfffFNm3hUdAzp48KCdd4MGDWzwmY3673//e2/7TO/HKL17q4S/22iYZWFKZWzcuNHOq2QZAk+KHhBCRsmG1fSESty9e1eGDh0q/fr1k9/+9rfeXXNmQ26OJb3xxhvyi1/8wobWH/7wB/n666/t8Y3IyEg73aJFi+zG3YSIKV999ZWkpqbK7du3H9meHTt2yI9//GNJSEiQN998U+Lj4+XYsWOyfft2+9y04fz583a6v/zlL2XqB6KNgwcPto/ffvut6+W7fv16SUpKsrsbAb8w9wMCqpN169aZe1g5O3fudC5fvuycPXvW2bRpk9OoUSMnJibGOXfunJ1uwoQJdrq3337bp/4//vEP+/r69et9Xs/MzPR5/dKlS05UVJTz8ssvO8XFxd7pFixYYKczn19iz5499jXzaNy9e9dJSUlxkpOTnWvXrvnMp/RnTZ8+3dZ7UCDaaJj2mOJWTk6O/bx58+a5rgtUhF1wqLaGDBkiTZo0sd/Kx44da3e3bdmyRZ5++mmf6aZNm+bzfPPmzRIXFycvvviiXLlyxVt69OhhP2PPnj12up07d9pexMyZM312jc2aNeuRbTO9FNNjMdPWr1/f573Sn1WRQLXR9Hwq2/sx2P0Gf2IXHKotc/zEDL9+6qmn7PGR9u3b28EApZn3zLGR0k6ePCkej0eaNm1a7udeunTJPn733Xf2sW3btj7vm9Azx3QeZ3dgp06dKvE/q5o2Pi5z3GfDhg32//LgwATgSRBAqLZ69erlHQVXkejo6DKhZA7umw17ybf6B5mNt7ZgaqM53mSCLj09vcrmifBAACHstG7d2u666tu3r8TExFQ4XXJysrc30qpVK+/rly9fLjMSrbx5GOacJLOrsCIV7Y6rijY+LhOCpp3jxo3zy+cBJTgGhLDzk5/8RO7duyfvvvtumffMqLn8/Hz7swkOM9Js9erVdjdUCTM0+lG6d+9uT5I105Z8XonSn1VyTtKD0wSqjW6HYd+5c8cejzKjCFu0aPHY9YDHQQ8IYeeFF16wQ5zNLqUjR47YIctmI256EWZja87TefXVV+1urjlz5tjpzHBqM8TZDC7461//Ko0bN37oPMxuP3NlhhEjRki3bt3sUGozHPv48eP2HJ2//e1vdjozqMAww6zNcPGaNWvaARWBaqPbYdimnVevXmXwAQKjwvFxQJAPw/7nP//50OnMEOQ6depU+P4f//hHp0ePHnbodr169ZzOnTvbYcbnz5/3TnPv3j1n6dKlTkJCgp1uwIABdkiyGcr8sGHYJfbv3++8+OKL9vNNW7p06eKsXr3a+74Zrj1z5kynSZMmTkRERJkh2f5sY2WGYY8dO9aJjIx0rl69+th1gMcVYf4JULYBAFAhjgEBAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABVBdyKquQaWuUeKuXnY41w1GAAQXMzZPdevX5fExMQy12IM6gAy4WMurw8AqN7MbdwfvBp9UO+CMz0fAED196jteY1A3qulZcuW9l72vXv3li+//PKx6rHbDQBCw6O25wEJoI8++kjS0tJk8eLF9v70Xbt2tRdaLLmJFgAAAbkYaa9evey97ktfLDExMdFJT09/ZF2Px2MvyEihUCgUqdbFbM8fxu89IHN/+sOHD/vchMuMgjDPs7Ozy0x/69YtKSgo8CkAgNDn9wC6cuWKvZFWs2bNfF43z/Py8spMb+5jEhcX5y2MgAOA8KA+Cm7+/Pni8Xi8xQzbAwCEPr+fB2Tuwmju6njx4kWf183z+Pj4MtNHR0fbAgAIL37vAUVFRdnbDO/atcvn6gbmeZ8+ffw9OwBANRWQKyGYIdgTJkyQZ599Vnr16iUrV66UoqIieeONNwIxOwBANRSQAHrttdfk8uXLsmjRIjvwoFu3bpKZmVlmYAIAIHxFmLHYEkTMMGwzGg4AUL2ZgWWxsbHBOwoOABCeCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAEBoBtGTJEomIiPApHTp08PdsAADV3FOB+NCOHTvKzp07/z+TpwIyGwBANRaQZDCBEx8fH4iPBgCEiIAcAzp58qQkJiZKq1atZPz48XLmzJkKp71165YUFBT4FABA6PN7APXu3VsyMjIkMzNT1q5dK6dPn5bnn39erl+/Xu706enpEhcX5y1JSUn+bhIAIAhFOI7jBHIG+fn5kpycLCtWrJBJkyaV2wMypYTpARFCAFD9eTweiY2NrfD9gI8OqF+/vrRr105OnTpV7vvR0dG2AADCS8DPAyosLJTc3FxJSEgI9KwAAOEcQHPmzJGsrCz59ttv5YsvvpBXXnlFatasKa+//rq/ZwUAqMb8vgvu3LlzNmyuXr0qTZo0kX79+smBAwfszwAAVNkgBLfMIAQzGg4AENqDELgWHABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUBvyEdqtarr77qus7kyZMrNa/z58+7rnPz5k3XddavX++6Tl5enlRGRTdOBOB/9IAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoiHMdxJIgUFBRIXFycdjOqrf/+97+u67Rs2VJCzfXr1ytV75tvvvF7W+Bf586dc11n+fLllZrXoUOHKlUP93k8HomNjZWK0AMCAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACg4imd2SJQJk+e7LpOly5dKjWvY8eOua7zzDPPuK7TvXt313UGDBgglfHcc8+5rnP27FnXdZKSkiSY3b1713Wdy5cvu66TkJAgVeHMmTOVqsfFSAOLHhAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVXIw0xOzatatK6lRWZmZmlcynQYMGlarXrVs313UOHz7suk7Pnj0lmN28edN1nf/85z9VckHbhg0buq6Tm5vrug4Cjx4QAEAFAQQAqB4BtG/fPhkxYoQkJiZKRESEbN261ed9x3Fk0aJF9j4fMTExMmTIEDl58qQ/2wwACMcAKioqkq5du8qaNWvKfX/58uWyatUq+eCDD+TgwYNSp04dGTp0aKX2KQMAQpfrQQjDhg2zpTym97Ny5Up55513ZOTIkfa1Dz/8UJo1a2Z7SmPHjn3yFgMAQoJfjwGdPn1a8vLy7G63EnFxcdK7d2/Jzs4ut86tW7ekoKDApwAAQp9fA8iEj2F6PKWZ5yXvPSg9Pd2GVElJSkryZ5MAAEFKfRTc/PnzxePxeMvZs2e1mwQAqG4BFB8fbx8vXrzo87p5XvLeg6KjoyU2NtanAABCn18DKCUlxQZN6TPrzTEdMxquT58+/pwVACDcRsEVFhbKqVOnfAYeHDlyxF4eo0WLFjJr1ix57733pG3btjaQFi5caM8ZGjVqlL/bDgAIpwA6dOiQDBw40Ps8LS3NPk6YMEEyMjJk3rx59lyhKVOmSH5+vvTr189e/6tWrVr+bTkAoFqLcMzJO0HE7LIzo+EAVC9jxoxxXefjjz92XScnJ8d1ndJfmt34/vvvK1UP95mBZQ87rq8+Cg4AEJ4IIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAANXjdgwAQl/Tpk1d13n//fdd16lRw/134GXLlrmuw1WtgxM9IACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACq4GCmAMqZPn+66TpMmTVzXuXbtmus6J06ccF0HwYkeEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABVcjBQIYX379q1UvbfffluqwqhRo1zXycnJCUhbUPXoAQEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFDBxUiBEDZ8+PBK1YuMjHRdZ9euXa7rZGdnu66D0EEPCACgggACAFSPANq3b5+MGDFCEhMTJSIiQrZu3erz/sSJE+3rpctLL73kzzYDAMIxgIqKiqRr166yZs2aCqcxgXPhwgVv2bhx45O2EwAQ7oMQhg0bZsvDREdHS3x8/JO0CwAQ4gJyDGjv3r3StGlTad++vUybNk2uXr1a4bS3bt2SgoICnwIACH1+DyCz++3DDz+0QzJ//etfS1ZWlu0x3bt3r9zp09PTJS4uzluSkpL83SQAQDicBzR27Fjvz507d5YuXbpI69atba9o8ODBZaafP3++pKWleZ+bHhAhBAChL+DDsFu1aiWNGzeWU6dOVXi8KDY21qcAAEJfwAPo3Llz9hhQQkJCoGcFAAjlXXCFhYU+vZnTp0/LkSNHpGHDhrYsXbpUxowZY0fB5ebmyrx586RNmzYydOhQf7cdABBOAXTo0CEZOHCg93nJ8ZsJEybI2rVr5ejRo/LnP/9Z8vPz7cmqqamp8u6779pdbQAAlIhwHMeRIGIGIZjRcAB8xcTEuK6zf//+Ss2rY8eOrusMGjTIdZ0vvvjCdR1UHx6P56HH9bkWHABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEAAgNG7JDSAw5s6d67rOj370o0rNKzMz03UdrmwNt+gBAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUMHFSAEFL7/8sus6CxcudF2noKBAKmPZsmWVqge4QQ8IAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACi5GCjyhRo0aua6zatUq13Vq1qzpus5nn30mlXHgwIFK1QPcoAcEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABRcjBZ7wgp+ZmZmu66SkpLiuk5ub67rOwoULXdcBqgo9IACACgIIABD8AZSeni49e/aUevXqSdOmTWXUqFFy4sQJn2lu3rwp06dPt/dIqVu3rowZM0YuXrzo73YDAMIpgLKysmy4mJtV7dixQ+7cuSOpqalSVFTknWb27Nny6aefyubNm+3058+fl9GjRwei7QCAcBmE8ODB1oyMDNsTOnz4sPTv3188Ho/86U9/kg0bNsigQYPsNOvWrZNnnnnGhtZzzz3n39YDAMLzGJAJHKNhw4b20QSR6RUNGTLEO02HDh2kRYsWkp2dXe5n3Lp1SwoKCnwKACD0VTqAiouLZdasWdK3b1/p1KmTfS0vL0+ioqKkfv36PtM2a9bMvlfRcaW4uDhvSUpKqmyTAADhEEDmWFBOTo5s2rTpiRowf/5825MqKWfPnn2izwMAhPCJqDNmzJDt27fLvn37pHnz5t7X4+Pj5fbt25Kfn+/TCzKj4Mx75YmOjrYFABBeXPWAHMex4bNlyxbZvXt3mbO5e/ToIZGRkbJr1y7va2aY9pkzZ6RPnz7+azUAILx6QGa3mxnhtm3bNnsuUMlxHXPsJiYmxj5OmjRJ0tLS7MCE2NhYmTlzpg0fRsABACodQGvXrrWPAwYM8HndDLWeOHGi/fl3v/ud1KhRw56Aaka4DR06VN5//303swEAhIEIx+xXCyJmGLbpSQEa2rVr57rO8ePHpSqMHDnSdR1zUjigxQwsM3vCKsK14AAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAA1eeOqECwS05OrlS9v//971IV5s6d67qOuQsxEEroAQEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFDBxUgRkqZMmVKpei1atJCqkJWV5bqO4zgBaQughR4QAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFVyMFEGvX79+ruvMnDkzIG0B4D/0gAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKjgYqQIes8//7zrOnXr1pWqkpub67pOYWFhQNoCVCf0gAAAKgggAEDwB1B6err07NlT6tWrJ02bNpVRo0bJiRMnfKYZMGCARERE+JSpU6f6u90AgHAKoKysLJk+fbocOHBAduzYIXfu3JHU1FQpKirymW7y5Mly4cIFb1m+fLm/2w0ACKdBCJmZmT7PMzIybE/o8OHD0r9/f+/rtWvXlvj4eP+1EgAQcp7oGJDH47GPDRs29Hl9/fr10rhxY+nUqZPMnz9fbty4UeFn3Lp1SwoKCnwKACD0VXoYdnFxscyaNUv69u1rg6bEuHHjJDk5WRITE+Xo0aPy1ltv2eNEn3zySYXHlZYuXVrZZgAAwi2AzLGgnJwc2b9/v8/rU6ZM8f7cuXNnSUhIkMGDB9tzJVq3bl3mc0wPKS0tzfvc9ICSkpIq2ywAQCgH0IwZM2T79u2yb98+ad68+UOn7d27t308depUuQEUHR1tCwAgvLgKIMdxZObMmbJlyxbZu3evpKSkPLLOkSNH7KPpCQEAUKkAMrvdNmzYINu2bbPnAuXl5dnX4+LiJCYmxu5mM+8PHz5cGjVqZI8BzZ49246Q69Kli5tZAQBCnKsAWrt2rfdk09LWrVsnEydOlKioKNm5c6esXLnSnhtkjuWMGTNG3nnnHf+2GgAQfrvgHsYEjjlZFQCAR+Fq2EAp//rXv1zXMaM83fr+++9d1wFCDRcjBQCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoCLCedQlrquYuSW3ub8QAKB683g8EhsbW+H79IAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoCLoAijILk0HAAjQ9jzoAuj69evaTQAAVMH2POiuhl1cXCznz5+XevXqSURERJkrZSclJcnZs2cfeoXVUMdyuI/lcB/L4T6WQ/AsBxMrJnwSExOlRo2K+zlPSZAxjW3evPlDpzELNZxXsBIsh/tYDvexHO5jOQTHcnic2+oE3S44AEB4IIAAACqqVQBFR0fL4sWL7WM4Yzncx3K4j+VwH8uh+i2HoBuEAAAID9WqBwQACB0EEABABQEEAFBBAAEAVBBAAAAV1SaA1qxZIy1btpRatWpJ79695csvv9RuUpVbsmSJvTxR6dKhQwcJdfv27ZMRI0bYy3qY//PWrVt93jcDORctWiQJCQkSExMjQ4YMkZMnT0q4LYeJEyeWWT9eeuklCSXp6enSs2dPe6mupk2byqhRo+TEiRM+09y8eVOmT58ujRo1krp168qYMWPk4sWLEm7LYcCAAWXWh6lTp0owqRYB9NFHH0laWpod2/7VV19J165dZejQoXLp0iUJNx07dpQLFy54y/79+yXUFRUV2d+5+RJSnuXLl8uqVavkgw8+kIMHD0qdOnXs+mE2ROG0HAwTOKXXj40bN0ooycrKsuFy4MAB2bFjh9y5c0dSU1Ptsikxe/Zs+fTTT2Xz5s12enNtydGjR0u4LQdj8uTJPuuD+VsJKk410KtXL2f69One5/fu3XMSExOd9PR0J5wsXrzY6dq1qxPOzCq7ZcsW7/Pi4mInPj7e+c1vfuN9LT8/34mOjnY2btzohMtyMCZMmOCMHDnSCSeXLl2yyyIrK8v7u4+MjHQ2b97snebYsWN2muzsbCdcloPxwgsvOG+++aYTzIK+B3T79m05fPiw3a1S+oKl5nl2draEG7NryeyCadWqlYwfP17OnDkj4ez06dOSl5fns36YiyCa3bThuH7s3bvX7pJp3769TJs2Ta5evSqhzOPx2MeGDRvaR7OtML2B0uuD2U3dokWLkF4fPA8shxLr16+Xxo0bS6dOnWT+/Ply48YNCSZBdzXsB125ckXu3bsnzZo183ndPD9+/LiEE7NRzcjIsBsX051eunSpPP/885KTk2P3BYcjEz5GeetHyXvhwux+M7uaUlJSJDc3VxYsWCDDhg2zG96aNWtKqDG3bpk1a5b07dvXbmAN8zuPioqS+vXrh836UFzOcjDGjRsnycnJ9gvr0aNH5a233rLHiT755BMJFkEfQPg/szEp0aVLFxtIZgX7+OOPZdKkSaptg76xY8d6f+7cubNdR1q3bm17RYMHD5ZQY46BmC9f4XActDLLYcqUKT7rgxmkY9YD8+XErBfBIOh3wZnuo/n29uAoFvM8Pj5ewpn5lteuXTs5deqUhKuSdYD1oyyzm9b8/YTi+jFjxgzZvn277Nmzx+f+YeZ3bnbb5+fnh8X6MKOC5VAe84XVCKb1IegDyHSne/ToIbt27fLpcprnffr0kXBWWFhov82YbzbhyuxuMhuW0uuHuSOkGQ0X7uvHuXPn7DGgUFo/zPgLs9HdsmWL7N692/7+SzPbisjISJ/1wex2MsdKQ2l9cB6xHMpz5MgR+xhU64NTDWzatMmOasrIyHD+/e9/O1OmTHHq16/v5OXlOeHkl7/8pbN3717n9OnTzueff+4MGTLEady4sR0BE8quX7/ufP3117aYVXbFihX25++++86+/6tf/cquD9u2bXOOHj1qR4KlpKQ4P/zwgxMuy8G8N2fOHDvSy6wfO3fudLp37+60bdvWuXnzphMqpk2b5sTFxdm/gwsXLnjLjRs3vNNMnTrVadGihbN7927n0KFDTp8+fWwJJdMesRxOnTrlLFu2zP7/zfpg/jZatWrl9O/f3wkm1SKAjNWrV9uVKioqyg7LPnDggBNuXnvtNSchIcEug6effto+NytaqNuzZ4/d4D5YzLDjkqHYCxcudJo1a2a/qAwePNg5ceKEE07LwWx4UlNTnSZNmthhyMnJyc7kyZND7ktaef9/U9atW+edxnzx+PnPf+40aNDAqV27tvPKK6/YjXM4LYczZ87YsGnYsKH9m2jTpo0zd+5cx+PxOMGE+wEBAFQE/TEgAEBoIoAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIBo+B8j/bsHMT/0QwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4)Develop a program to recognize digits using CNN.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "plt.imshow(x_test[0].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Predicted: {predictions[0].argmax()}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5153300d-d7eb-4cbe-96e2-fee9407d755c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 177ms/step - accuracy: 0.3315 - loss: 1.0993\n",
      "Epoch 2/3\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 184ms/step - accuracy: 0.4132 - loss: 1.0929\n",
      "Epoch 3/3\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 188ms/step - accuracy: 0.5447 - loss: 0.9570\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.3314 - loss: 1.2032\n",
      "Test accuracy: 0.3323\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
      "Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "# 5).Create an RNN-based sentiment analysis system to classify text reviews (such as movie reviews or product reviews) into positive, negative, or neutral \n",
    "# sentiments. Use datasets containing labeled text data for training and testing the model's accuracy in sentiment classification\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "max_words = 10000  \n",
    "max_len = 200   \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words)\n",
    "\n",
    "\n",
    "y_train = np.random.choice([0, 1, 2], size=len(y_train))  \n",
    "y_test = np.random.choice([0, 1, 2], size=len(y_test))\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(3, activation='softmax')  # 3 classes: Negative, Neutral, Positive\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=64)\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "review = \"This movie was fantastic!\"\n",
    "review_seq = [imdb.get_word_index().get(word, 0) for word in review.lower().split()]\n",
    "review_seq = pad_sequences([review_seq], maxlen=max_len)  # Ensure review is in a list of lists\n",
    "\n",
    "prediction = model.predict(review_seq)\n",
    "sentiment = ['Negative', 'Neutral', 'Positive'][prediction.argmax()]  # Map output to sentiment label\n",
    "print(f\"Sentiment: {sentiment}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cbfb9b3-7586-47cb-b20a-a847c6fd6093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 172ms/step - accuracy: 0.5805 - loss: 0.6837\n",
      "Epoch 2/3\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 180ms/step - accuracy: 0.8533 - loss: 0.3421\n",
      "Epoch 3/3\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 183ms/step - accuracy: 0.9225 - loss: 0.2032\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.8693 - loss: 0.3131\n",
      "Test accuracy: 0.8720\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# Develop a program to forecast future values in time series data, such as weather patterns, using RNN models like LSTM or GRU\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "max_words = 10000 \n",
    "max_len = 200 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words)\n",
    "\n",
    "y_train = [1 if label == 1 else 0 for label in y_train]  \n",
    "y_test = [1 if label == 1 else 0 for label in y_test]  \n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(3, activation='softmax')  \n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=64)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Corrected part to handle review\n",
    "review = \"This movie was fantastic!\"\n",
    "review_seq = [imdb.get_word_index().get(word, 0) for word in review.lower().split()]\n",
    "review_seq = pad_sequences([review_seq], maxlen=max_len)  # Make it a list of lists\n",
    "\n",
    "prediction = model.predict(review_seq)\n",
    "sentiment = ['Negative', 'Neutral', 'Positive'][prediction.argmax()]  \n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf9322-00f7-43ee-9ae6-be808f9dacd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
